import asyncio
from typing import Optional, Dict, Any, List, Tuple
from datetime import datetime
from contextlib import asynccontextmanager
import time
import re
import json

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from langchain_mcp_adapters.tools import load_mcp_tools
from langgraph.prebuilt import create_react_agent
from langchain_ollama import ChatOllama
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate

# Configuration
print("ğŸ“‹ ã‚¹ã‚¯ãƒªãƒ—ãƒˆåˆæœŸåŒ–é–‹å§‹...")
SERVER_PARAMS = StdioServerParameters(
    command="npx",  # Use npx directly if it's in your PATH
    args=["@playwright/mcp@latest"],
)
print(f"ğŸ“‹ MCP ã‚µãƒ¼ãƒãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šå®Œäº†: {SERVER_PARAMS.command} {' '.join(SERVER_PARAMS.args or [])}")

# Models
print("ğŸ¤– ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ä¸­...")
EXECUTION_MODEL = ChatOllama(
    model="qwen2.5:14b",
    temperature=0.1,
    base_url="http://localhost:11434",
)
print(f"ğŸ¤– å®Ÿè¡Œãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†: {EXECUTION_MODEL.model}")

PLANNING_MODEL = ChatOllama(
    model="qwen2.5:14b",
    temperature=0.2,
    base_url="http://localhost:11434",
)
print(f"ğŸ¤– è¨ˆç”»ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†: {PLANNING_MODEL.model}")

# Enhanced templates for browser navigation
print("ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆèª­ã¿è¾¼ã¿ä¸­...")
PLANNING_TEMPLATE = """
ã‚ãªãŸã¯ã‚¦ã‚§ãƒ–æ¤œç´¢ã®å°‚é–€å®¶ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«æœ€é©ãªæ¤œç´¢æˆ¦ç•¥ã‚’ç«‹ã¦ã¦ãã ã•ã„ã€‚

è³ªå•: {query}

ä»¥ä¸‹ã®ãƒ„ãƒ¼ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã§ã™:
{tools}

æ¤œç´¢æˆ¦ç•¥ã‚’æ¬¡ã®å½¢å¼ã§æä¾›ã—ã¦ãã ã•ã„:
1. æ¤œç´¢ã™ã‚‹æƒ…å ±ã®æ˜ç¢ºåŒ–ï¼ˆä½•ã‚’æ­£ç¢ºã«çŸ¥ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ï¼‰
2. ä½¿ç”¨ã™ã¹ãæ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆè¤‡æ•°ã®å€™è£œã€å„ªå…ˆé †ä½ä»˜ãï¼‰
3. ç¢ºèªã™ã¹ãæƒ…å ±æºï¼ˆä¾‹ï¼šå…¬å¼ã‚µã‚¤ãƒˆã€ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚µã‚¤ãƒˆã€æ¯”è¼ƒã‚µã‚¤ãƒˆãªã©ï¼‰
4. æƒ…å ±åé›†ã®é †åºï¼ˆã©ã®ãƒšãƒ¼ã‚¸ã‚’ã„ã¤è¦‹ã‚‹ã¹ãã‹ï¼‰
5. æˆåŠŸã®åŸºæº–ï¼ˆã©ã®ã‚ˆã†ãªæƒ…å ±ãŒè¦‹ã¤ã‹ã‚Œã°ååˆ†ã‹ï¼‰

æˆ¦ç•¥:
"""

# Enhanced execution template with more explicit browser navigation instructions
EXECUTION_TEMPLATE = """
ã‚ãªãŸã¯ã‚¦ã‚§ãƒ–ãƒ–ãƒ©ã‚¦ã‚¶ã‚’æ“ä½œã—ã¦æƒ…å ±ã‚’åé›†ã™ã‚‹ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®æ¤œç´¢æˆ¦ç•¥ã«å¾“ã£ã¦ã€å¿…è¦ãªæƒ…å ±ã‚’åé›†ã—ã¦ãã ã•ã„ã€‚

æ¤œç´¢æˆ¦ç•¥:
{plan}

ç¾åœ¨ã®ãƒ–ãƒ©ã‚¦ã‚¶çŠ¶æ…‹:
{browser_state}

ä»¥ä¸‹ã®æ‰‹é †ã§æƒ…å ±åé›†ã‚’é€²ã‚ã¦ãã ã•ã„:
1. ã¾ãšã€Œæ€è€ƒã€: æ¬¡ã«ä½•ã‚’ã™ã‚‹ã¹ãã‹ã€ç¾åœ¨ã®çŠ¶æ…‹ã‹ã‚‰è€ƒãˆã¦ãã ã•ã„
2. ã€Œè¡Œå‹•ã€: é©åˆ‡ãªãƒ–ãƒ©ã‚¦ã‚¶æ“ä½œãƒ„ãƒ¼ãƒ«ã‚’é¸æŠã—ã¦å®Ÿè¡Œã—ã¦ãã ã•ã„
3. ã€Œè¦³å¯Ÿã€: ãƒ–ãƒ©ã‚¦ã‚¶ã«è¡¨ç¤ºã•ã‚ŒãŸæƒ…å ±ã‚’ç¢ºèªã—ã€é‡è¦ãªæƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„
4. ã€Œæ¬¡ã®è¡Œå‹•ã€: å¿…è¦ãªæƒ…å ±ãŒå¾—ã‚‰ã‚Œã‚‹ã¾ã§ã€ç•°ãªã‚‹webãƒšãƒ¼ã‚¸ã‚’æ¢ç´¢ã—ç¶šã‘ã¦ãã ã•ã„

é‡è¦ãªæƒ…å ±ã‚’è¦‹ã¤ã‘ãŸã‚‰ã€ä»¥ä¸‹ã®å½¢å¼ã§æ•´ç†ã—ã¦ãã ã•ã„:
- è¦‹å‡ºã—: [ãƒˆãƒ”ãƒƒã‚¯]
- èª¬æ˜: [è©³ç´°æƒ…å ±]
- æƒ…å ±æº: [URL]

æ¢ç´¢ã®æµã‚Œ:
1. æœ€åˆã¯æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ (https://www.google.com) ã‹ã‚‰é–‹å§‹ã—ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢
2. æ¤œç´¢çµæœã‹ã‚‰è¤‡æ•°ã®æœ‰æœ›ãªã‚µã‚¤ãƒˆã‚’é¸ã³ã€ãã‚Œãã‚Œé–²è¦§ã—ã¦æƒ…å ±ã‚’åé›†
3. å°‘ãªãã¨ã‚‚3ã¤ä»¥ä¸Šã®ç•°ãªã‚‹ã‚½ãƒ¼ã‚¹ã‹ã‚‰æƒ…å ±ã‚’åé›†ã™ã‚‹ã“ã¨
4. å…¬å¼ã‚µã‚¤ãƒˆã‚„ä¿¡é ¼æ€§ã®é«˜ã„ã‚½ãƒ¼ã‚¹ã‚’å„ªå…ˆã™ã‚‹ã“ã¨

æœ€å¾Œã«ã€åé›†ã—ãŸæƒ…å ±å…¨ä½“ã‚’è¦ç´„ã—ã¦æä¾›ã—ã¦ãã ã•ã„ã€‚
"""

# New function to capture browser state
BROWSER_STATE_TEMPLATE = """
ãƒ–ãƒ©ã‚¦ã‚¶çŠ¶æ…‹ã‚’è©³ç´°ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
ç¾åœ¨è¡¨ç¤ºã—ã¦ã„ã‚‹ãƒšãƒ¼ã‚¸ã®ã‚¿ã‚¤ãƒˆãƒ«ã€URLã€ä¸»è¦ãªè¦ç´ ï¼ˆè¦‹å‡ºã—ã€ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒ•ã‚©ãƒ¼ãƒ ãªã©ï¼‰ã‚’å«ã‚ã¦ãã ã•ã„ã€‚
ã“ã®æƒ…å ±ã¯æ¬¡ã®ãƒ–ãƒ©ã‚¦ã‚¶æ“ä½œã®è¨ˆç”»ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚
"""

class WebSearchAgent:
    """Enhanced web search agent with improved browser control flow"""
    
    def __init__(self):
        print("ğŸ”„ WebSearchAgent ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆä¸­...")
        self.query = ""
        self.plan = None
        self.result = None
        self.evaluation = None
        self.visited_urls = set()
        self.execution_history = []
        self.browser_state = "ãƒ–ãƒ©ã‚¦ã‚¶ã¯ã¾ã èµ·å‹•ã—ã¦ã„ã¾ã›ã‚“ã€‚"
        self.current_url = None
        self.current_page_title = None
        self.current_page_content = None
        print("ğŸ”„ WebSearchAgent ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åˆæœŸåŒ–å®Œäº†")
    
    @asynccontextmanager
    async def connect_session(self):
        """Connect to the MCP server with proper resource management"""
        print("ğŸ”Œ MCP ã‚µãƒ¼ãƒãƒ¼ã¸ã®æ¥ç¶šã‚’é–‹å§‹...")
        start_time = time.time()
        
        try:
            print("ğŸ”Œ stdio_client ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ã‚’é–‹å§‹...")
            async with stdio_client(SERVER_PARAMS) as transport:
                print(f"ğŸ”Œ stdio_client æ¥ç¶šå®Œäº† ({time.time() - start_time:.2f}ç§’)")
                read_stream, write_stream = transport
                print(f"ğŸ”Œ ã‚¹ãƒˆãƒªãƒ¼ãƒ å–å¾—å®Œäº†: èª­ã¿è¾¼ã¿/æ›¸ãè¾¼ã¿ã‚¹ãƒˆãƒªãƒ¼ãƒ æº–å‚™å®Œäº†")
                
                async with ClientSession(read_stream, write_stream) as session:
                    print("ğŸ”Œ ClientSession ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆå®Œäº†")
                    try:
                        print("ğŸ”Œ ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–ä¸­...")
                        init_start = time.time()
                        await session.initialize()
                        print(f"ğŸ”Œ ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–å®Œäº† ({time.time() - init_start:.2f}ç§’)")
                        
                        print("ğŸ”Œ MCP ãƒ„ãƒ¼ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
                        tools_start = time.time()
                        tools = await load_mcp_tools(session)
                        print(f"ğŸ”Œ MCP ãƒ„ãƒ¼ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {len(tools)}å€‹ã®ãƒ„ãƒ¼ãƒ«ãŒåˆ©ç”¨å¯èƒ½ ({time.time() - tools_start:.2f}ç§’)")
                        
                        print(f"ğŸ”Œ åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«ä¸€è¦§:")
                        for i, tool in enumerate(tools):
                            print(f"   {i+1}. {tool.name}: {tool.description[:50]}...")
                        
                        yield session, tools
                    finally:
                        print("ğŸ”Œ ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆçµ‚äº†")
        except Exception as e:
            print(f"âŒ MCP ã‚µãƒ¼ãƒãƒ¼æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            raise
        finally:
            print(f"ğŸ”Œ MCP ã‚µãƒ¼ãƒãƒ¼æ¥ç¶šå‡¦ç†å®Œäº† (åˆè¨ˆæ™‚é–“: {time.time() - start_time:.2f}ç§’)")
    
    async def create_search_plan(self, tools):
        """Use the planning model to create a search strategy"""
        print("\nğŸ” æ¤œç´¢è¨ˆç”»ã®ä½œæˆé–‹å§‹...")
        start_time = time.time()
        
        tools_description = "\n".join([f"- {tool.name}: {tool.description}" for tool in tools])
        print(f"ğŸ” ãƒ„ãƒ¼ãƒ«èª¬æ˜ã‚’ç”Ÿæˆ: {len(tools)}å€‹ã®ãƒ„ãƒ¼ãƒ«èª¬æ˜ã‚’å«ã‚€")
        
        planning_prompt = ChatPromptTemplate.from_messages([
            SystemMessage(content="You are a web search planning expert."),
            HumanMessage(content=PLANNING_TEMPLATE.format(query=self.query, tools=tools_description))
        ])
        print(f"ğŸ” è¨ˆç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆå®Œäº†: {len(planning_prompt.format_messages())}ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸")
        
        print("\n=== æ¤œç´¢è¨ˆç”»ã®ä½œæˆä¸­... ===\n")
        print(f"ğŸ” è¨ˆç”»ãƒ¢ãƒ‡ãƒ«å‘¼ã³å‡ºã—é–‹å§‹...")
        invoke_start = time.time()
        response = await PLANNING_MODEL.ainvoke(planning_prompt.format_messages())
        print(f"ğŸ” è¨ˆç”»ãƒ¢ãƒ‡ãƒ«å‘¼ã³å‡ºã—å®Œäº† ({time.time() - invoke_start:.2f}ç§’)")
        
        self.plan = response.content
        print(f"ğŸ” æ¤œç´¢è¨ˆç”»å–å¾—: {len(self.plan)}æ–‡å­—")
        
        print("\n=== æ¤œç´¢è¨ˆç”»ã®å†…å®¹ ===\n")
        print(self.plan)
        print(f"\nğŸ” æ¤œç´¢è¨ˆç”»ä½œæˆå®Œäº† (åˆè¨ˆæ™‚é–“: {time.time() - start_time:.2f}ç§’)")
        return self.plan
    
    async def get_browser_state(self, session, tools):
        """Get current browser state using the snapshot tool"""
        # Find snapshot tool
        snapshot_tool = next((tool for tool in tools if tool.name == "browser_snapshot"), None)
        if not snapshot_tool:
            return "ãƒ–ãƒ©ã‚¦ã‚¶ã®çŠ¶æ…‹ã‚’å–å¾—ã§ãã¾ã›ã‚“: snapshot ãƒ„ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            
        try:
            # Take snapshot
            print("ğŸ” ãƒ–ãƒ©ã‚¦ã‚¶çŠ¶æ…‹ã®å–å¾—ã‚’è©¦ã¿ã¦ã„ã¾ã™...")
            snapshot_result = await snapshot_tool.invoke({"selector": "body"})
            
            # Get current URL
            url_tool = next((tool for tool in tools if tool.name == "browser_navigate"), None)
            if url_tool:
                # We can't directly get the URL, so we use the page title as an indicator
                title_result = await snapshot_tool.invoke({"selector": "title"})
                page_title = title_result.get("value", {}).get("name", "ä¸æ˜ãªãƒšãƒ¼ã‚¸")
                self.current_page_title = page_title
                
            # Process snapshot
            if isinstance(snapshot_result, dict) and "value" in snapshot_result:
                snapshot_data = snapshot_result["value"]
                self.current_page_content = json.dumps(snapshot_data, ensure_ascii=False)
                
                # Extract basic page info
                page_info = []
                page_info.append(f"ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«: {self.current_page_title}")
                
                # Extract main content elements (headings, links, etc.)
                elements = []
                if "children" in snapshot_data:
                    self._extract_elements(snapshot_data, elements)
                
                # Prepare state summary
                state_summary = "\n".join([
                    "=== ç¾åœ¨ã®ãƒ–ãƒ©ã‚¦ã‚¶çŠ¶æ…‹ ===",
                    f"ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«: {self.current_page_title}",
                    f"ä¸»è¦è¦ç´ æ•°: {len(elements)}ä»¶",
                    "ä¸»è¦è¦ç´ :",
                    "\n".join([f"- {elem}" for elem in elements[:10]]),
                    "==========================="
                ])
                
                self.browser_state = state_summary
                print(f"ğŸ” ãƒ–ãƒ©ã‚¦ã‚¶çŠ¶æ…‹ã‚’å–å¾—ã—ã¾ã—ãŸ: {len(state_summary)}æ–‡å­—")
                return state_summary
            else:
                return "ãƒ–ãƒ©ã‚¦ã‚¶ã®çŠ¶æ…‹ã‚’æ­£å¸¸ã«å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ"
        except Exception as e:
            print(f"âŒ ãƒ–ãƒ©ã‚¦ã‚¶çŠ¶æ…‹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return f"ãƒ–ãƒ©ã‚¦ã‚¶çŠ¶æ…‹å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
    
    def _extract_elements(self, node, elements, max_elements=10):
        """Helper to extract important elements from snapshot"""
        if len(elements) >= max_elements:
            return
            
        if isinstance(node, dict):
            # Check if this is an important element
            node_name = node.get("name", "")
            node_role = node.get("role", "")
            node_value = node.get("value", "")
            
            # Add headings, links, and important elements
            if node_role in ["heading", "link", "button", "textbox", "combobox"]:
                if isinstance(node_value, str) and node_value.strip():
                    elements.append(f"{node_role}: {node_value[:50]}")
                else:
                    elements.append(f"{node_role}: {node_name[:50]}")
            
            # Process children
            if "children" in node and isinstance(node["children"], list):
                for child in node["children"]:
                    self._extract_elements(child, elements, max_elements)
    
    async def execute_search(self, session, tools, max_attempts=5):
        """Execute the search using the ReAct agent with improved browser state tracking"""
        print("\nğŸŒ æ¤œç´¢å®Ÿè¡Œã‚’é–‹å§‹...")
        start_time = time.time()
        
        if not self.plan:
            print("ğŸŒ æ¤œç´¢è¨ˆç”»ãŒã‚ã‚Šã¾ã›ã‚“ã€‚æ¤œç´¢è¨ˆç”»ã‚’ä½œæˆã—ã¾ã™...")
            await self.create_search_plan(tools)
        
        # Get initial browser state
        initial_browser_state = await self.get_browser_state(session, tools)
            
        execution_prompt = ChatPromptTemplate.from_messages([
            SystemMessage(content="You are a web browsing assistant that carefully follows instructions."),
            HumanMessage(content=EXECUTION_TEMPLATE.format(
                plan=self.plan,
                browser_state=initial_browser_state
            ))
        ])
        print(f"ğŸŒ å®Ÿè¡Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆå®Œäº†: {len(execution_prompt.format_messages())}ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸")
        
        initial_messages = execution_prompt.format_messages()
        print("ğŸŒ ReActã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆä¸­...")
        agent_start = time.time()
        agent = create_react_agent(EXECUTION_MODEL, tools)
        print(f"ğŸŒ ReActã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆå®Œäº† ({time.time() - agent_start:.2f}ç§’)")
        
        # Track attempts
        attempt = 0
        satisfactory_result = False
        current_messages = [{"role": msg.type, "content": msg.content} for msg in initial_messages]
        print(f"ğŸŒ åˆæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¨­å®š: {len(current_messages)}ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸")
        
        collected_data = []
        
        while attempt < max_attempts and not satisfactory_result:
            attempt += 1
            print(f"\n=== æ¤œç´¢è©¦è¡Œ {attempt}/{max_attempts} ===\n")
            attempt_start = time.time()
            
            # Invoke the agent
            print(f"ğŸŒ è©¦è¡Œ {attempt}: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‘¼ã³å‡ºã—é–‹å§‹...")
            agent_invoke_start = time.time()
            agent_response = await agent.ainvoke({"messages": current_messages})
            print(f"ğŸŒ è©¦è¡Œ {attempt}: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‘¼ã³å‡ºã—å®Œäº† ({time.time() - agent_invoke_start:.2f}ç§’)")
            
            # Record the execution
            last_messages = agent_response.get("messages", [])
            self.execution_history.append(last_messages)
            print(f"ğŸŒ è©¦è¡Œ {attempt}: {len(last_messages)}å€‹ã®æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ä¿¡")
            
            # Extract and print the agent's thought process
            print(f"ğŸŒ è©¦è¡Œ {attempt}: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’æŠ½å‡º...")
            thought_found = False
            for msg in last_messages:
                if hasattr(msg, 'content') and isinstance(msg.content, str) and "Thought:" in msg.content:
                    thought_parts = msg.content.split('Thought:')
                    for part in thought_parts[1:]:
                        thought_text = part.split('Action:')[0].strip() if 'Action:' in part else part.strip()
                        print(f"\nğŸ¤” ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹: ")
                        print(f"{thought_text}")
                        thought_found = True
            
            if not thought_found:
                print("ğŸŒ æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            
            # Update the browser state after actions
            updated_browser_state = await self.get_browser_state(session, tools)
            
            # Check if we've found good information
            print(f"ğŸŒ è©¦è¡Œ {attempt}: çµæœã®è©•ä¾¡ä¸­...")
            last_ai_message = None
            for msg in reversed(last_messages):
                if hasattr(msg, 'content') and isinstance(msg.content, str) and not (
                    "Thought:" in msg.content or 
                    "Action:" in msg.content or 
                    "Observation:" in msg.content
                ):
                    last_ai_message = msg
                    break
            
            if last_ai_message:
                print(f"ğŸŒ è©¦è¡Œ {attempt}: æœ€å¾Œã®AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {len(last_ai_message.content)}æ–‡å­—")
                
                # Extract URLs from the response
                print(f"ğŸŒ è©¦è¡Œ {attempt}: URLæŠ½å‡ºä¸­...")
                url_count = 0
                for line in last_ai_message.content.split('\n'):
                    if "http" in line:
                        try:
                            url_part = line.split("http")[1].split()[0].strip(",.)()")
                            url = "http" + url_part
                            self.visited_urls.add(url)
                            url_count += 1
                        except IndexError:
                            pass  # Skip malformed URLs
                print(f"ğŸŒ è©¦è¡Œ {attempt}: {url_count}å€‹ã®URLã‚’æŠ½å‡º")
                
                # Extract potentially useful information
                if "è¦‹å‡ºã—:" in last_ai_message.content or "æƒ…å ±æº:" in last_ai_message.content:
                    collected_data.append(last_ai_message.content)
                        
                # Simple heuristic for determining if we have a satisfactory result
                content_length = len(last_ai_message.content.split())
                has_sources = "æƒ…å ±æº" in last_ai_message.content or "URL" in last_ai_message.content
                has_details = content_length > 150
                
                print(f"ğŸŒ è©¦è¡Œ {attempt}: å“è³ªè©•ä¾¡ - æ–‡å­—æ•°: {content_length}, æƒ…å ±æºã‚ã‚Š: {has_sources}, è©³ç´°ã‚ã‚Š: {has_details}")
                
                # Success criteria: We have detailed information with sources from multiple sites
                if len(collected_data) >= 3:
                    satisfactory_result = True
                    # Combine all collected data
                    self.result = "\n\n".join([
                        "=== åé›†ã—ãŸæƒ…å ± ===",
                        *collected_data,
                        f"\n=== æƒ…å ±æº ===\nè¨ªå•ã—ãŸURL: {', '.join(list(self.visited_urls))}"
                    ])
                    print(f"\nâœ… è©¦è¡Œ {attempt}: ååˆ†ãªæƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ\n")
                    break
                elif has_details and has_sources:
                    # If we have detailed info from one source, continue but mark as potentially satisfactory
                    print(f"ğŸŒ è©¦è¡Œ {attempt}: ä¸€éƒ¨ã®æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ - è¿½åŠ ã®æƒ…å ±æºã‚’æ¢ã—ã¾ã™")
                else:
                    print(f"ğŸŒ è©¦è¡Œ {attempt}: æƒ…å ±ãŒä¸ååˆ†ã§ã™ - æ¬¡ã®è©¦è¡Œã¸é€²ã¿ã¾ã™")
            else:
                print(f"ğŸŒ è©¦è¡Œ {attempt}: AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            # If not satisfactory, add guidance for the next attempt
            if not satisfactory_result:
                print(f"ğŸŒ è©¦è¡Œ {attempt}: æ¬¡ã®è©¦è¡Œã®ãŸã‚ã®æŒ‡ç¤ºã‚’è¿½åŠ ...")
                next_instruction = {
                    "role": "user",
                    "content": f"ç¾åœ¨ã®çŠ¶æ…‹: {updated_browser_state}\n\n" +
                             f"ã“ã‚Œã¾ã§ã«åé›†ã—ãŸæƒ…å ±: {len(collected_data)}ä»¶\n" +
                             f"è¨ªå•ã—ãŸURLæ•°: {len(self.visited_urls)}\n\n" +
                             f"æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:\n" +
                             f"1. ç•°ãªã‚‹æƒ…å ±æºã‚’æ¢ç´¢ã™ã‚‹ï¼ˆã¾ã è¨ªå•ã—ã¦ã„ãªã„ã‚µã‚¤ãƒˆï¼‰\n" +
                             f"2. ä»¥ä¸‹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢ã‚’è¡Œã†: {self.query} æœ€æ–°æƒ…å ±\n" +
                             f"3. æƒ…å ±ã‚’è¦‹ã¤ã‘ãŸã‚‰ã€Œè¦‹å‡ºã—:ã€ã€Œèª¬æ˜:ã€ã€Œæƒ…å ±æº:ã€ã®å½¢å¼ã§æŠ½å‡ºã™ã‚‹\n" +
                             f"4. å°‘ãªãã¨ã‚‚3ã¤ã®ç•°ãªã‚‹æƒ…å ±æºã‹ã‚‰æƒ…å ±ã‚’åé›†ã™ã‚‹"
                }
                current_messages = agent_response["messages"] + [next_instruction]
                print(f"ğŸŒ è©¦è¡Œ {attempt}: æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°: {len(current_messages)}")
            
            print(f"ğŸŒ è©¦è¡Œ {attempt} å®Œäº† (æ‰€è¦æ™‚é–“: {time.time() - attempt_start:.2f}ç§’)")
        
        # If we didn't find a satisfactory result but collected some data
        if not satisfactory_result and collected_data:
            self.result = "\n\n".join([
                "=== ä¸ååˆ†ãªãŒã‚‰åé›†ã—ãŸæƒ…å ± ===",
                *collected_data,
                f"\n=== æƒ…å ±æº ===\nè¨ªå•ã—ãŸURL: {', '.join(list(self.visited_urls))}"
            ])
        
        print("\n=== æ¤œç´¢çµæœ ===\n")
        if self.result:
            print(f"âœ… æ¤œç´¢çµæœ: {len(self.result)}æ–‡å­—")
            print(self.result)
        else:
            print("âŒ ååˆ†ãªæƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        
        print(f"\nğŸŒ æ¤œç´¢å®Ÿè¡Œå®Œäº† (åˆè¨ˆæ™‚é–“: {time.time() - start_time:.2f}ç§’, è©¦è¡Œå›æ•°: {attempt})")
        return self.result
        
    async def run_full_search(self, query: str, max_attempts: int = 5):
        """Run the complete search process with proper resource management"""
        print(f"\nğŸš€ å®Œå…¨æ¤œç´¢ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹: ã‚¯ã‚¨ãƒªã€Œ{query}ã€")
        overall_start = time.time()
        
        self.query = query
        print(f"ğŸš€ æ¤œç´¢ã‚¯ã‚¨ãƒªè¨­å®š: {self.query}")
        
        print(f"ğŸš€ MCP ã‚»ãƒƒã‚·ãƒ§ãƒ³æ¥ç¶šã‚’é–‹å§‹...")
        connect_start = time.time()
        async with self.connect_session() as (session, tools):
            print(f"ğŸš€ MCP ã‚»ãƒƒã‚·ãƒ§ãƒ³æ¥ç¶šå®Œäº† ({time.time() - connect_start:.2f}ç§’)")
            
            print(f"ğŸš€ æ¤œç´¢è¨ˆç”»ä½œæˆã‚’é–‹å§‹...")
            plan_start = time.time()
            await self.create_search_plan(tools)
            print(f"ğŸš€ æ¤œç´¢è¨ˆç”»ä½œæˆå®Œäº† ({time.time() - plan_start:.2f}ç§’)")
            
            print(f"ğŸš€ æ¤œç´¢å®Ÿè¡Œã‚’é–‹å§‹...")
            execute_start = time.time()
            await self.execute_search(session, tools, max_attempts)
            print(f"ğŸš€ æ¤œç´¢å®Ÿè¡Œå®Œäº† ({time.time() - execute_start:.2f}ç§’)")
            
        print(f"\nğŸš€ å®Œå…¨æ¤œç´¢ãƒ—ãƒ­ã‚»ã‚¹å®Œäº† (åˆè¨ˆæ™‚é–“: {time.time() - overall_start:.2f}ç§’)")
        
        return {
            "query": self.query,
            "plan": self.plan,
            "result": self.result,
            "visited_urls": list(self.visited_urls),
            "attempts": len(self.execution_history),
            "total_time": time.time() - overall_start
        }

async def main():
    """Main function to run the web search agent"""
    print("\n====== WebSearchAgent ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œé–‹å§‹ ======\n")
    main_start = time.time()
    
    search_agent = WebSearchAgent()
    
    try:
        # Get query from user or use default
        default_query = "æœ€æ–°ã®NVIDIAã®GPUã®æƒ…å ±"
        query_input = input(f"æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆã¾ãŸã¯ Enter ã§ã€Œ{default_query}ã€ï¼‰: ")
        query = query_input or default_query

        print(f"âœ… å…¥åŠ›ç¢ºèª: ã€Œ{query}ã€")
        print("ğŸ” æ¤œç´¢ã‚’é–‹å§‹ã—ã¾ã™...")
        
        search_start = time.time()
        report = await search_agent.run_full_search(query)
        search_time = time.time() - search_start
        
        print("\n====== æ¤œç´¢ã‚µãƒãƒªãƒ¼ ======")
        print(f"ã‚¯ã‚¨ãƒª: {report['query']}")
        print(f"è©¦è¡Œå›æ•°: {report['attempts']}")
        print(f"è¨ªå•URLæ•°: {len(report['visited_urls'])}")
        print(f"è¨ªå•ã—ãŸURL: {', '.join(report['visited_urls'][:3])}{'...' if len(report['visited_urls']) > 3 else ''}")
        print(f"æ¤œç´¢æ™‚é–“: {search_time:.2f}ç§’")
        
    except Exception as e:
        print(f"\nâš ï¸ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        print("\nè©³ç´°ãªã‚¨ãƒ©ãƒ¼ãƒ­ã‚°:")
        import traceback
        traceback.print_exc()
    finally:
        print(f"\n====== WebSearchAgent ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œå®Œäº† (åˆè¨ˆæ™‚é–“: {time.time() - main_start:.2f}ç§’) ======\n")

if __name__ == "__main__":
    print("ğŸš€ ãƒ¡ã‚¤ãƒ³é–¢æ•°ã‚’å®Ÿè¡Œã—ã¾ã™...")
    asyncio.run(main())
    print("ğŸ ãƒ¡ã‚¤ãƒ³é–¢æ•°ã®å®Ÿè¡ŒãŒå®Œäº†ã—ã¾ã—ãŸ")